{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15e0192",
   "metadata": {},
   "source": [
    "> # PART ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf08cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60836e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(data  ,  k):\n",
    "    #return k-random points of the data dataframe \n",
    "    #these points are the initial centroids\n",
    "    return data.sample(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc443344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(data,Points):\n",
    "    k = len(Points)\n",
    "    #calculating the distance between each feature and the point\n",
    "    #for k == 3 we have 3 distances as k is the number of cluster or centroids\n",
    "    #for k == 5 we have 5 distances as k is the number of cluster or centroids\n",
    "    if k == 3:\n",
    "        data['dist1'] = abs(data['Height']-Points.iloc[0][0])+abs(data['Weight']-Points.iloc[0][1])+abs(data['BMI']-Points.iloc[0][2])+abs(data['Shoulders']-Points.iloc[0][3])+abs(data['Arms']-Points.iloc[0][4])\n",
    "        data['dist2'] = abs(data['Height']-Points.iloc[1][0])+abs(data['Weight']-Points.iloc[1][1])+abs(data['BMI']-Points.iloc[1][2])+abs(data['Shoulders']-Points.iloc[1][3])+abs(data['Arms']-Points.iloc[1][4])\n",
    "        data['dist3'] = abs(data['Height']-Points.iloc[2][0])+abs(data['Weight']-Points.iloc[2][1])+abs(data['BMI']-Points.iloc[2][2])+abs(data['Shoulders']-Points.iloc[2][3])+abs(data['Arms']-Points.iloc[2][4])\n",
    "    elif k == 5:\n",
    "        data['dist1'] = abs(data['Height']-Points.iloc[0][0])+abs(data['Weight']-Points.iloc[0][1])+abs(data['BMI']-Points.iloc[0][2])+abs(data['Shoulders']-Points.iloc[0][3])+abs(data['Arms']-Points.iloc[0][4])\n",
    "        data['dist2'] = abs(data['Height']-Points.iloc[1][0])+abs(data['Weight']-Points.iloc[1][1])+abs(data['BMI']-Points.iloc[1][2])+abs(data['Shoulders']-Points.iloc[1][3])+abs(data['Arms']-Points.iloc[1][4])\n",
    "        data['dist3'] = abs(data['Height']-Points.iloc[2][0])+abs(data['Weight']-Points.iloc[2][1])+abs(data['BMI']-Points.iloc[2][2])+abs(data['Shoulders']-Points.iloc[2][3])+abs(data['Arms']-Points.iloc[2][4])\n",
    "        data['dist4'] = abs(data['Height']-Points.iloc[3][0])+abs(data['Weight']-Points.iloc[3][1])+abs(data['BMI']-Points.iloc[3][2])+abs(data['Shoulders']-Points.iloc[3][3])+abs(data['Arms']-Points.iloc[3][4])\n",
    "        data['dist5'] = abs(data['Height']-Points.iloc[4][0])+abs(data['Weight']-Points.iloc[4][1])+abs(data['BMI']-Points.iloc[4][2])+abs(data['Shoulders']-Points.iloc[4][3])+abs(data['Arms']-Points.iloc[4][4])\n",
    "    else:\n",
    "        add_dist(data,Points) #its only used if k != 3 or 5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc837983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dist(data,Points):\n",
    "    #we can only use this function but it will be slower so I have checked first if K==3 or 5 as it is required in the description\n",
    "    k = len(Points)\n",
    "    for i in range(k):\n",
    "        data[f'dist{ i+1 }'] = abs(data['Height']-Points.iloc[i][0])+abs(data['Weight']-Points.iloc[i][1])+abs(data['BMI']-Points.iloc[i][2])+abs(data['Shoulders']-Points.iloc[i][3])+abs(data['Arms']-Points.iloc[i][4])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02747a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid(data):\n",
    "    #this function returns the centroids by geting the mean of each cluster\n",
    "    l = len( data['Old_Cluster'].value_counts().index )\n",
    "    point = []\n",
    "    for i in range(l):\n",
    "        cluster = data['Old_Cluster'].value_counts().index[i]\n",
    "        x = data[data['Old_Cluster'] == cluster].mean()\n",
    "        point.append(x)\n",
    "    point = pd.DataFrame(point)\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e855488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data,k):\n",
    "    start_time = time.time() #saving the initial time\n",
    "    \n",
    "    Points = get_points(data,k) #getting the initial centroids which are random points\n",
    "    dist(data,Points)           #calculating the distances between each points and centroids and add these distances to the dataframe\n",
    "    distances = data.iloc[:,5:] #getting the a sub-dataframe containing the distances of each points to the centroinds\n",
    "    data['Old_Cluster'] = distances.apply(lambda x: distances.columns[x.argmin()], axis = 1) #check the minimum distances and put the columnd name the a new column in the dataframe called old cluster\n",
    "    \n",
    "    \n",
    "    Points = get_centroid(data) #get the centroids after the first cluster and repeat the previous step but this time we will store the minimum distances in a new colums called the new cluster\n",
    "    dist(data,Points)\n",
    "    distances = data.iloc[:,5:-1] \n",
    "    data['New_Cluster'] = distances.apply(lambda x: distances.columns[x.argmin()], axis = 1)\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        if( data['New_Cluster'].equals(data['Old_Cluster']) ): #compare the new cluster to the old cluster\n",
    "            break                                           #if both clusters are equal to every feature so it is the stopping point\n",
    "        data['Old_Cluster'] = data['New_Cluster']      #if they're not equall we put the new cluster in the old cluster and start to get new centroids\n",
    "        \n",
    "        Points = get_centroid(data)                  #getting the centroids and cluster the data until the new cluster == the old cluster\n",
    "        dist(data,Points)\n",
    "        distances = data.iloc[:,5:-2] \n",
    "        data['New_Cluster'] = distances.apply(lambda x: distances.columns[x.argmin()], axis = 1)\n",
    "           \n",
    "    return time.time()-start_time               #return the duration of clutstering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b3bfb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.541115522384644 seconds\n",
      "134.06875658035278 seconds\n",
      "252.44965815544128 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15784/1877619763.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m                                            \u001b[1;31m#empty array to save the time taken for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m         \u001b[1;31m#calculate the time for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"seconds\"\u001b[0m\u001b[1;33m)\u001b[0m                           \u001b[1;31m#print the time taken for each sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m                                   \u001b[1;31m#store the time in the array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15784/3992083902.py\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(data, k)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'New_Cluster'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m               \u001b[1;31m#return the duration of clutstering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7767\u001b[0m         )\n\u001b[1;32m-> 7768\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15784/3992083902.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mPoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'New_Cluster'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m               \u001b[1;31m#return the duration of clutstering\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36margmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_minmax_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_argmax_with_skipna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\al-fajr\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanargmin\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m   1072\u001b[0m     \"\"\"\n\u001b[0;32m   1073\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value_typ\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"+inf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1075\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_arg_null_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('group14.csv',names=['Height','Weight','BMI','Shoulders','Arms']) #read the file\n",
    "df = (df - df.mean() )/df.std()                   #normalize the data\n",
    "samples = np.arange(20000,100000+1,20000)         #getting samples 20000,40000,60000,80000,100000\n",
    "k = 3                                             #no of clusters\n",
    "r = []                                            #empty array to save the time taken for each sample\n",
    "for i in range( len(samples) ):\n",
    "    m = k_means( df.sample(samples[i]),k)         #calculate the time for each sample\n",
    "    print( m,\"seconds\")                           #print the time taken for each sample\n",
    "    r.append(m)                                   #store the time in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf8d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('group14.csv',names=['Height','Weight','BMI','Shoulders','Arms'])\n",
    "df = (df - df.mean() )/df.std()\n",
    "samples = np.arange(20000,100000+1,20000)\n",
    "k = 5\n",
    "r = []\n",
    "for i in range( len(samples) ):\n",
    "    m = k_means( df.sample(samples[i]),k)\n",
    "    print( m,\"seconds\")\n",
    "    r.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafae781",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff9938",
   "metadata": {},
   "source": [
    "> ##### In 3 we are required to calculate the complexity from the code. And as we have nested loops it is o(N^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61af26",
   "metadata": {},
   "source": [
    "> #### From the time taken to samples size (Complexity) for both graphs cluster 3 , 5 are more likely to be linear O(N)\n",
    "> #### It is not O(N^2) because the number as the number of iterations are not large compared to the size of the data set\n",
    "> #### Also we can see ups and downs this is because the randomness of getting the first initial centroids if they are near to the centroids and if we plot more samples it will be more likely to be a linear graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
